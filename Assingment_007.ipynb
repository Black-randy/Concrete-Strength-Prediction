{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "8-WS5eOwi6If"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title **Step 0 :** Get Necessary Libraries\n",
        "!pip install seaborn\n",
        "!pip install wget pandas\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import wget\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import clear_output\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ar1RXZnaluGe",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2KQICIcedDu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **Step 1 :** Download From Github and Organize Data\n",
        "\n",
        "# Install wget and pandas (if not already installed)\n",
        "\n",
        "\n",
        "# Function to download and organize data\n",
        "def download_and_organize_data():\n",
        "\n",
        "    # URLs of the files on GitHub\n",
        "\n",
        "    # url_concrete = \"https://raw.githubusercontent.com/Black-randy/Concrete-Strength-Prediction/main/concrete.csv\"\n",
        "    url_concrete_data_yeh = \"https://raw.githubusercontent.com/Black-randy/Concrete-Strength-Prediction/main/Concrete_Data_Yeh.csv\"\n",
        "\n",
        "    # Specify the destination paths in Google Colab\n",
        "    destination_path_train = \"/content/train_data/Concrete_Data_Yeh.csv\"\n",
        "    # destination_path_test = \"/content/test_data/concrete.csv\"\n",
        "\n",
        "    # Create folders for test and train data\n",
        "    os.makedirs(\"/content/train_data\", exist_ok=True)\n",
        "    # os.makedirs(\"/content/test_data\", exist_ok=True)\n",
        "\n",
        "    # Download the files\n",
        "    wget.download(url_concrete_data_yeh, destination_path_train)\n",
        "    # wget.download(url_concrete, destination_path_test)\n",
        "    clear_output()\n",
        "    # Print a message indicating the completion of the download and organization\n",
        "    print(\"Files downloaded and organized into train_data and test_data folders.\")\n",
        "\n",
        "# Download and organize data\n",
        "download_and_organize_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Step 2 :** Load Data into Pandas DataFrames\n",
        "# Function to load data into Pandas DataFrames\n",
        "def load_data_into_dataframes():\n",
        "    # Assign values to train_data_path and test_data_path\n",
        "    train_data_path = \"/content/train_data\"\n",
        "    # test_data_path = \"/content/test_data\"\n",
        "\n",
        "    # Load CSV files into Pandas DataFrames\n",
        "    train_df = pd.read_csv(os.path.join(train_data_path, \"Concrete_Data_Yeh.csv\"))\n",
        "    # test_df = pd.read_csv(os.path.join(test_data_path, \"concrete.csv\"))\n",
        "\n",
        "    # Clear previous outputs\n",
        "    clear_output()\n",
        "\n",
        "    # Print the assigned values and display a preview of the DataFrames\n",
        "    print(f\"train_data_path: {train_data_path}\")\n",
        "    # print(f\"test_data_path: {test_data_path}\")\n",
        "\n",
        "    # Return the DataFrames\n",
        "    return train_df # ,test_df\n",
        "\n",
        "# Load data into Pandas DataFrames\n",
        "train_df = load_data_into_dataframes()\n"
      ],
      "metadata": {
        "id": "p5huPkcwf1dt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Step 2.1 :** Train DataFrame info\n",
        "\n",
        "print(\"\\nShape of the data :-\\n\")\n",
        "rows_count, columns_count = train_df.shape\n",
        "print('Total Number of rows :', rows_count)\n",
        "print('Total Number of columns :', columns_count)\n",
        "\n",
        "# Display a preview of the train DataFrame\n",
        "print(\"\\n\\nPreview of train DataFrame:\\n\")\n",
        "display(train_df.head(10))\n",
        "\n",
        "\n",
        "# Display data types of each attribute in the train DataFrame\n",
        "train_data_types = train_df.dtypes\n",
        "print(\"\\n\\nData Types of Attributes in Train DataFrame:\\n\")\n",
        "print(train_data_types)\n",
        "\n",
        "# Check for missing values in the train DataFrame\n",
        "missing_values_train = train_df.isnull().sum()\n",
        "\n",
        "# Check for missing values in the test DataFrame\n",
        "# missing_values_test = test_df.isnull().sum()\n",
        "\n",
        "# Display the results\n",
        "print(\"\\n\\nMissing Values in Train DataFrame:\\n\")\n",
        "print(missing_values_train[missing_values_train > 0])\n",
        "\n",
        "# print(\"\\nMissing Values in Test DataFrame:\")\n",
        "# print(missing_values_test[missing_values_test > 0])\n",
        "\n",
        "# Display descriptive statistics for the train DataFrame\n",
        "train_descriptive_stats = train_df.describe()\n",
        "\n",
        "# Display descriptive statistics for the test DataFrame\n",
        "# test_descriptive_stats = test_df.describe()\n",
        "\n",
        "# Print the results\n",
        "print(\"\\n\\nDescriptive Statistics for Train DataFrame:\")\n",
        "print(train_descriptive_stats)\n",
        "\n",
        "# print(\"\\nDescriptive Statistics for Test DataFrame:\")\n",
        "# print(test_descriptive_stats)"
      ],
      "metadata": {
        "id": "X_GnBh67XxdP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Step 3 :** Visualize Feature Importances\n",
        "\n",
        "# Concatenate train and test data for modeling\n",
        "combined_df = pd.concat([train_df], ignore_index=True)\n",
        "# combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "\n",
        "# Separate features and target variable\n",
        "X = combined_df.drop(columns=['csMPa'])\n",
        "y = combined_df['csMPa']\n",
        "\n",
        "# Create a Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "rf_model.fit(X, y)\n",
        "\n",
        "# Get feature importances\n",
        "feature_importances = rf_model.feature_importances_\n",
        "\n",
        "# Create a DataFrame to hold feature names and their importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort features by importance in descending order\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Plot the feature importances\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
        "plt.xlabel('Importance')\n",
        "plt.title('Feature Importances')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "tYi9jFr7j0jg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Pair Plot of All Columns\n",
        "\n",
        "#Set the style of seaborn\n",
        "# sns.set(style=\"ticks\")\n",
        "\n",
        "#Create a pair plot for all columns\n",
        "# plt.figure(figsize=(18, 15))\n",
        "# sns.pairplot(combined_df, markers=\"h\", diag_kind='kde')\n",
        "# plt.suptitle(\"Pair Plot of All Columns\", y=1.02, fontsize=20)\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "wsuRqO1BqSG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualize Outliers\n",
        "\n",
        "# Set the style of seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Select relevant columns for visualization\n",
        "columns_of_interest = ['cement', 'slag', 'flyash', 'water', 'superplasticizer', 'coarseaggregate', 'fineaggregate', 'age', 'csMPa']\n",
        "\n",
        "# Create a horizontal box plot for each column to visualize outliers\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.boxplot(data=combined_df[columns_of_interest], orient=\"h\", palette=\"Set2\", dodge=False)\n",
        "plt.title('Horizontal Box Plot of Features to Visualize Outliers')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "AUAMfvU8lFBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Outliers Visualization**\n",
        "---"
      ],
      "metadata": {
        "id": "_S30YVRjYmjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# @title Outliers Visualization\n",
        "features_of_interest = ['cement', 'slag', 'flyash', 'water', 'superplasticizer', 'coarseaggregate', 'fineaggregate', 'age', 'csMPa']\n",
        "\n",
        "# Set the style of seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(6,6))\n",
        "\n",
        "# Flatten the axes for easy iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through each feature and create histograms and boxplots\n",
        "for i, feature in enumerate(features_of_interest):\n",
        "    sns.histplot(train_df[feature], kde=True, ax=axes[i])\n",
        "    axes[i].set_xlabel(feature, fontsize=8)\n",
        "    axes[i].set_title(f\"{feature} Distribution Plot\", fontsize=8)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Box plots for each feature\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(6,6))\n",
        "\n",
        "# Flatten the axes for easy iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through each feature and create boxplots\n",
        "for i, feature in enumerate(features_of_interest):\n",
        "    sns.boxplot(train_df[feature], ax=axes[i])\n",
        "    axes[i].set_xlabel(feature, fontsize=8)\n",
        "    axes[i].set_title(f\"{feature} Box Plot\", fontsize=8)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MjPDB7WhXFMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cement Outliers Visualization\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
        "fig.set_size_inches(10,3)\n",
        "\n",
        "sns.histplot(train_df['cement'], ax=ax1, kde=True)\n",
        "ax1.tick_params(labelsize=15)\n",
        "ax1.set_xlabel('Cement', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['cement'], ax=ax2)\n",
        "ax2.set_title(\"Box Plot\")\n",
        "ax2.set_xlabel('Cement', fontsize=15)\n"
      ],
      "metadata": {
        "id": "26YE9mw95rhq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Slag Outliers Visualization\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
        "fig.set_size_inches(10,3)\n",
        "sns.histplot(train_df['slag'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Slag', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['slag'], ax=ax2)\n",
        "ax2.set_xlabel('Slag', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")"
      ],
      "metadata": {
        "id": "joctOSG-7dCC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Flyash Outliers Visualization\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
        "fig.set_size_inches(10,3)\n",
        "sns.histplot(train_df['flyash'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Flyash', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['flyash'], ax=ax2)\n",
        "ax2.set_xlabel('Flyash', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")\n"
      ],
      "metadata": {
        "id": "G6bVFOqL_kjb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Water Outliers Visualization\n",
        "# Water\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
        "fig.set_size_inches(10,3)\n",
        "sns.histplot(train_df['water'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Water', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['water'], ax=ax2)\n",
        "ax2.set_xlabel('Water', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")"
      ],
      "metadata": {
        "id": "kv-7knxL_oC_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Superplasticizer Outliers Visualization\n",
        "# Superplasticizer\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
        "fig.set_size_inches(10,3)\n",
        "\n",
        "sns.histplot(train_df['superplasticizer'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Superplasticizer', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['superplasticizer'], ax=ax2)\n",
        "ax2.set_xlabel('Superplasticizer', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")\n"
      ],
      "metadata": {
        "id": "WgQruWQlAX_B",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Coarseagg Outliers Visualization\n",
        "# Coarseagg\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
        "fig.set_size_inches(10,3)\n",
        "sns.histplot(train_df['coarseaggregate'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Coarseagg', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['coarseaggregate'], ax=ax2)\n",
        "ax2.set_xlabel('Coarseagg', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")"
      ],
      "metadata": {
        "id": "wIIowI4HC5qf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Fineaggregate Outliers Visualization\n",
        "# Fineaggregate\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
        "fig.set_size_inches(10,3)\n",
        "sns.histplot(train_df['fineaggregate'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Fineagg', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['fineaggregate'], ax=ax2)\n",
        "ax2.set_xlabel('Fineagg', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")"
      ],
      "metadata": {
        "id": "2MhNDHQEC6s_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Age Outliers Visualization\n",
        "# Age\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
        "fig.set_size_inches(10,3)\n",
        "sns.histplot(train_df['age'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Age', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['age'], ax=ax2)\n",
        "ax2.set_xlabel('Age', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")\n",
        "\n",
        "Q1_age = train_df['age'].quantile(0.25)\n",
        "Q3_age = train_df['age'].quantile(0.75)\n",
        "IQR_age = Q3_age - Q1_age\n",
        "LTV_age = Q1_age - 1.5 * IQR_age\n",
        "UTV_age = Q3_age + 1.5 * IQR_age"
      ],
      "metadata": {
        "id": "k0FXO9TUC-M6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Strength Outliers Visualization\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
        "fig.set_size_inches(10,3)\n",
        "sns.histplot(train_df['csMPa'], ax=ax1, kde=True)\n",
        "ax1.tick_params(labelsize=15)\n",
        "ax1.set_xlabel('Strength', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['csMPa'], ax=ax2)\n",
        "ax2.set_title(\"Box Plot\")\n",
        "ax2.set_xlabel('Strength', fontsize=15)"
      ],
      "metadata": {
        "id": "I9Ew0b1wDFpK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fixing Outliers**\n",
        "---"
      ],
      "metadata": {
        "id": "nEIhNTTgMtyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new DataFrame for fixing outliers\n",
        "train_df_new = train_df.copy()\n",
        "\n",
        "# Iterate over each column (excluding the last one, assuming it's the target variable)\n",
        "for col_name in train_df_new.columns[:-1]:\n",
        "    q1 = train_df_new[col_name].quantile(0.25)\n",
        "    q3 = train_df_new[col_name].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    low = q1 - 1.5 * iqr\n",
        "    high = q3 + 1.5 * iqr\n",
        "\n",
        "    # Replace values outside the lower and upper bounds with the median of the column\n",
        "    train_df_new.loc[(train_df_new[col_name] < low) | (train_df_new[col_name] > high), col_name] = train_df_new[col_name].median()\n",
        "\n",
        "# Set the style of seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot boxplot after fixing outliers\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.boxplot(data=train_df_new, orient=\"h\", palette=\"Set2\", dodge=False)\n",
        "plt.title('Box Plot after Fixing Outliers')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9mhOIavBUufI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Calculate the correlation matrix\n",
        "# train_df_new.corr() //// ----------- for insight\n",
        "\n",
        "correlation_matrix = train_df_new.corr()\n",
        "\n",
        "# Create a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "\n",
        "# Set up the matplotlib figure with seaborn style\n",
        "with sns.axes_style(\"white\"):\n",
        "    plt.figure(figsize=(12, 10))\n",
        "\n",
        "    # Draw the heatmap with the mask\n",
        "    sns.heatmap(correlation_matrix,cmap=\"RdPu\", annot=True, fmt=\".2f\", linewidths=\".5\")\n",
        "\n",
        "    # Set the title\n",
        "    plt.title(\"Correlation Matrix for Train DataFrame\", fontsize=16)\n",
        "\n",
        "# The plot will be shown automatically when the code block is executed\n"
      ],
      "metadata": {
        "id": "uxv1_LD3Wkoc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  KMeans clustering algorithm to find the optimal number of clusters\n",
        "\n",
        "cluster_range = range(2, 6)\n",
        "cluster_errors = []\n",
        "\n",
        "for num_clusters in cluster_range:\n",
        "    clusters_df = KMeans(num_clusters, n_init=5)\n",
        "    clusters_df.fit(train_df_new)\n",
        "    labels = clusters_df.labels_\n",
        "    centroids = clusters_df.cluster_centers_\n",
        "    cluster_errors.append(clusters_df.inertia_)\n",
        "\n",
        "clusters_df = pd.DataFrame({\"num_clusters\": cluster_range, \"cluster_errors\": cluster_errors})\n",
        "print(clusters_df)\n",
        "# Elbow plot\n",
        "plt.figure(figsize=(4, 3))\n",
        "plt.plot(clusters_df.num_clusters, clusters_df.cluster_errors, marker=\"o\")\n",
        "plt.title('Elbow Plot for Optimal Number of Clusters')\n",
        "plt.xlabel('Number of Clusters')\n",
        "plt.ylabel('Cluster Errors (Inertia)')\n",
        "print('\\n')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "TQ9PLNejcfR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Assigne cluster IDs to each data point\n",
        "num_clusters = 3 # @param {type:\"integer\"}\n",
        "\n",
        "# Create a KMeans model with the specified number of clusters\n",
        "kmeans_model = KMeans(n_clusters=num_clusters, random_state=2354)\n",
        "\n",
        "# Fit the model to the training data\n",
        "kmeans_model.fit(train_df_new)\n",
        "\n",
        "# Predict the cluster labels for each data point\n",
        "cluster_labels = kmeans_model.predict(train_df_new)\n",
        "\n",
        "# Assign the cluster labels to the original DataFrame\n",
        "train_df_new[\"Cluster_id\"] = cluster_labels\n",
        "\n",
        "# Create a deep copy of the DataFrame with cluster assignments\n",
        "train_df_new_clustered = train_df_new.copy(deep=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Ujq2EQZlfUTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# already fitted a KMeans model named 'kmeans_model'\n",
        "centroids = kmeans_model.cluster_centers_\n",
        "\n",
        "# 'centroids' is now a NumPy array containing the coordinates of the cluster centers\n",
        "print(\"Cluster Centers:\")\n",
        "centroids\n",
        "\n",
        "# centroids_df = pd.DataFrame(centroids, columns=train_df_new.columns[:-1])  # Exclude the 'Cluster_id' column\n",
        "# print(\"Cluster Centers (DataFrame):\")\n",
        "# print(centroids_df)"
      ],
      "metadata": {
        "id": "5RLprSWVl5kJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import zscore\n",
        "\n",
        "train_df_Scaled = train_df_new.apply(zscore)\n",
        "# display(train_df_Scaled.head(5))\n",
        "# print('\\n')\n",
        "# plt.figure(figsize=(6,3))\n",
        "# sns.boxplot(data=train_df_Scaled, orient=\"h\", palette=\"Set2\", dodge=False)\n"
      ],
      "metadata": {
        "id": "Zl0aEBLylB0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Negelect theese**"
      ],
      "metadata": {
        "id": "8-WS5eOwi6If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "jTm55spvcVIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_new.head()"
      ],
      "metadata": {
        "id": "YI_dIm_BcFuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_Scaled.head()"
      ],
      "metadata": {
        "id": "7UYJOXe6bs0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA** Test Splitting"
      ],
      "metadata": {
        "id": "dz7mRqCt7gu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Step xx :** Separating  **csMPa**  --- not in use\n",
        "# x = train_df_new.drop(columns=['csMPa'])\n",
        "# y = train_df_new['csMPa']"
      ],
      "metadata": {
        "cellView": "form",
        "id": "biygdVu4rvzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# @title **Step xx :** Separating  **csMPa** (Scaled)\n",
        "y = train_df_Scaled['csMPa']\n",
        "x = train_df_Scaled.drop(columns=['csMPa'])\n",
        "\n",
        "# Perform train-test split\n",
        "x_model_train, x_test, y_model_train, y_test = train_test_split(x, y, test_size=0.2, random_state=7)\n",
        "\n",
        "# Display the shapes of the resulting data sets\n",
        "print('x_train data shape :{}'.format(x_model_train.shape))\n",
        "print('y_train data shape :{}'.format(y_model_train.shape))\n",
        "print('x_test data shape  :{}'.format(x_test.shape))\n",
        "print('y_test data shape  :{}'.format(y_test.shape))\n"
      ],
      "metadata": {
        "id": "WLrw9vQ09FEA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Step xx :** Separating  **csMPa** (Scaled)\n",
        "# Perform train-test split\n",
        "x_train, x_validate, y_train, y_validate = train_test_split(x_model_train, y_model_train, test_size=0.3, random_state=7)\n",
        "\n",
        "# Display the shapes of the resulting data sets\n",
        "print('x_train data shape :{}'.format(x_train.shape))\n",
        "print('y_train data shape :{}'.format(y_train.shape))\n",
        "print('x_test data shape  :{}'.format(x_validate.shape))\n",
        "print('y_test data shape  :{}'.format(y_validate.shape))\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WVpLGqwKvkTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Models**"
      ],
      "metadata": {
        "id": "26M5UvXuIMiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Defining the kFold function for the cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "# Define the number of splits and random state\n",
        "n_splits = 10\n",
        "random_state = 7\n",
        "\n",
        "# Set the random seed using numpy\n",
        "np.random.seed(random_state)\n",
        "\n",
        "# Create a KFold object with shuffle=False\n",
        "kfold = KFold(n_splits=n_splits, shuffle=False)\n",
        "\n",
        "linear_model = []\n",
        "linear_model_score = []\n",
        "linear_model_RMSE = []\n",
        "linear_model_R_2 = []\n",
        "Model = []\n",
        "RMSE = []\n",
        "R_sq = []"
      ],
      "metadata": {
        "id": "BUaHZK1tkedP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Model X.1 :** Linear Regression Model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# Initialize Linear Regression model\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Fit the Linear Regression model on the training data\n",
        "regression_model.fit(x_train, y_train)\n",
        "\n",
        "# Append the model name to the list\n",
        "linear_model.append('Linear Regression')\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*13 + \"Linear Regression Model\" + \"-\"*13 + \"\\n\")\n",
        "\n",
        "# Display coefficients for each independent attribute\n",
        "for idx, col_name in enumerate(x_train.columns):\n",
        "    print(\"The coefficient for {} is:{} \".format(col_name, regression_model.coef_[idx]))\n",
        "\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Display the intercept for the model\n",
        "intercept = regression_model.intercept_\n",
        "print(\"Model intercept is {}\".format(intercept))\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "lr_score = regression_model.score(x_validate, y_validate)\n",
        "linear_model_score.append(lr_score)\n",
        "print(\"Linear Regression Model Score:\", lr_score)\n",
        "\n",
        "# Calculate RMSE using cross-validation\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=7)\n",
        "lr_rmse = np.sqrt((-1) * cross_val_score(regression_model, x_train, y_train.values.ravel(), cv=kfold, scoring='neg_mean_squared_error').mean())\n",
        "print(\"Linear Regression Model RMSE :\", lr_rmse)\n",
        "\n",
        "# Append RMSE to the list\n",
        "linear_model_RMSE.append(lr_rmse)\n",
        "\n",
        "# Calculate R-squared using cross-validation\n",
        "lr_r2 = cross_val_score(regression_model, x_train, y_train.values.ravel(), cv=kfold, scoring='r2').mean()\n",
        "print(\"Linear Regression Model R-Square Value :\", lr_r2)\n",
        "\n",
        "# Append R-squared to the list\n",
        "linear_model_R_2.append(lr_r2)\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Scatter plot with labels and title\n",
        "#   plt.figure(figsize=(5, 5))\n",
        "#   plt.scatter(y_test, y_predict, alpha=0.5)\n",
        "#   plt.title(\"Actual vs Predicted Concrete Strength\")\n",
        "#   plt.xlabel(\"Actual Concrete Strength\")\n",
        "#   plt.ylabel(\"Predicted Concrete Strength\")\n",
        "#   plt.show()\n"
      ],
      "metadata": {
        "id": "tyBRdE2vtZ5N",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Model X.2 :** Multilinear Regression Model\n",
        "\n",
        "# Import necessary libraries for Multilinear Regression\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Initialize Multilinear Regression model\n",
        "mlr_model = LinearRegression()\n",
        "\n",
        "# Fit the Multilinear Regression model on the training data\n",
        "mlr_model.fit(x_train, y_train)\n",
        "\n",
        "# Append the model name to the list\n",
        "linear_model.append('Multilinear Regression')\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*13 + \"Multilinear Regression Model\" + \"-\"*13 + \"\\n\")\n",
        "\n",
        "# Display coefficients for each independent attribute\n",
        "print(\"Coefficients for each independent attribute:\")\n",
        "for idx, col_name in enumerate(x_train.columns):\n",
        "    print(\"The coefficient for {} is: {}\".format(col_name, mlr_model.coef_[idx]))\n",
        "\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "mlr_score = mlr_model.score(x_validate, y_validate)\n",
        "linear_model_score.append(mlr_score)\n",
        "print(\"Multilinear Regression Model Score:\", mlr_score)\n",
        "\n",
        "# Calculate RMSE using cross-validation\n",
        "mlr_rmse = np.sqrt((-1) * cross_val_score(mlr_model, x_train, y_train.values.ravel(), cv=kfold, scoring='neg_mean_squared_error').mean())\n",
        "print(\"Multilinear Regression Model RMSE :\", mlr_rmse)\n",
        "\n",
        "# Append RMSE to the list\n",
        "linear_model_RMSE.append(mlr_rmse)\n",
        "\n",
        "# Calculate R-squared using cross-validation\n",
        "mlr_r2 = cross_val_score(mlr_model, x_train, y_train.values.ravel(), cv=kfold, scoring='r2').mean()\n",
        "print(\"Multilinear Regression Model R-Square Value :\", mlr_r2)\n",
        "\n",
        "# Append R-squared to the list\n",
        "linear_model_R_2.append(mlr_r2)\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AbMBBvxRSmYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <del> **Model xx :**  Train Random Forest Classifier. </del>\n",
        "\n",
        "'''\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Convert the target variable to binary labels for classification\n",
        "threshold = 1\n",
        "y_train_class = (y_train > threshold).astype(int)\n",
        "y_test_class = (y_test > threshold).astype(int)\n",
        "\n",
        "# Create and fit the Random Forest Classifier model\n",
        "rf_classifier_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier_model.fit(x_train, y_train_class)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_predict_class = rf_classifier_model.predict(x_test)\n",
        "\n",
        "# Evaluate the Random Forest Classifier performance\n",
        "accuracy = accuracy_score(y_test_class, y_predict_class)\n",
        "classification_rep = classification_report(y_test_class, y_predict_class)\n",
        "conf_matrix = confusion_matrix(y_test_class, y_predict_class)\n",
        "\n",
        "# Print performance metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_rep)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=['Not High Strength', 'High Strength'],\n",
        "            yticklabels=['Not High Strength', 'High Strength'])\n",
        "plt.title('Confusion Matrix for Random Forest Classifier')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()'''\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "586fsWV6UdIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-adding Random  and modifying -"
      ],
      "metadata": {
        "id": "3zN8Qmt73UNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Model X.3 :** Random Forest Regressor Model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "n_estimators = [int(x) for x in np.linspace(start = 10 , stop = 100, num = 3)]\n",
        "# Create a Random Forest Regressor\n",
        "rfTree = RandomForestRegressor()\n",
        "\n",
        "# Fit the Random Forest Regressor on the training data\n",
        "rfTree.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*13 + \"Random Forest Regressor Model\" + \"-\"*13 + \"\\n\")\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "rfTree_train_score = rfTree.score(x_train, y_train)\n",
        "print(\"Random Forest Regressor Model Training Set Score:\", rfTree_train_score)\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "rfTree_score = rfTree.score(x_validate, y_validate)\n",
        "linear_model_score.append(rfTree_score)\n",
        "print(\"Random Forest Regressor Model Validation Set Score:\", rfTree_score)\n",
        "\n",
        "# Calculate RMSE using cross-validation\n",
        "rfTree_rmse = np.sqrt((-1) * cross_val_score(rfTree, x_train, y_train.values.ravel(), cv=kfold, scoring='neg_mean_squared_error').mean())\n",
        "print(\"Random Forest Regressor Model RMSE:\", rfTree_rmse)\n",
        "\n",
        "# Calculate R-squared using cross-validation\n",
        "rfTree_r2 = cross_val_score(rfTree, x_train, y_train.values.ravel(), cv=kfold, scoring='r2').mean()\n",
        "print(\"Random Forest Regressor Model R-Square Value:\", rfTree_r2)\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Create a DataFrame with model metrics\n",
        "rfTree_model_df = pd.DataFrame({'Trainng Score': [rfTree_train_score],\n",
        "                                'Validation Score': [rfTree_score],\n",
        "                                'RMSE': [rfTree_rmse],\n",
        "                                'R Squared': [rfTree_r2]})\n",
        "display(rfTree_model_df)\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "rfTree_test_score = rfTree.score(x_test, y_test)\n",
        "print(\"Random Forest Regressor Model Test Data Set Score:\", rfTree_test_score)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e7dPlkA92KPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Model X.3.1 :** Hyper-tuning Random Forest Regressor -  **Gridsearch CV**\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "import sys\n",
        "\n",
        "# Define the parameter distribution\n",
        "param_dist = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [10],\n",
        "    'max_features': ['log2'],\n",
        "    'min_samples_leaf': [1, 2, 3],\n",
        "    'min_samples_split': sp_randint(5, 11),\n",
        "    'n_estimators': sp_randint(50, 71)\n",
        "}\n",
        "\n",
        "# Create a Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(random_state=7)\n",
        "\n",
        "# Create RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=10, cv=kfold, n_jobs=1, verbose=0, return_train_score=True, random_state=7)\n",
        "\n",
        "# Redirect standard output to capture progress\n",
        "original_stdout = sys.stdout\n",
        "sys.stdout = sys.stderr\n",
        "\n",
        "# Fit the random search to the data\n",
        "print(\"Fitting RandomizedSearchCV...\")\n",
        "random_search.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "# Reset standard output\n",
        "sys.stdout = original_stdout\n",
        "\n",
        "# Get the best parameters and model\n",
        "best_params = random_search.best_params_\n",
        "best_rf_model = random_search.best_estimator_\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Fit the best model on the training set\n",
        "best_rf_model.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "best_rf_score_val = best_rf_model.score(x_validate, y_validate)\n",
        "print(\"Best Random Forest Regressor Model Validation Set Score:\", best_rf_score_val)\n",
        "\n",
        "# Calculate RMSE using cross-validation\n",
        "best_rf_rmse = np.sqrt((-1) * cross_val_score(best_rf_model, x_train, y_train.values.ravel(), cv=kfold, scoring='neg_mean_squared_error').mean())\n",
        "print(\"Best Random Forest Regressor Model RMSE:\", best_rf_rmse)\n",
        "\n",
        "# Calculate R-squared using cross-validation\n",
        "best_rf_r2 = cross_val_score(best_rf_model, x_train, y_train.values.ravel(), cv=kfold, scoring='r2').mean()\n",
        "print(\"Best Random Forest Regressor Model R-Square Value:\", best_rf_r2)\n",
        "\n",
        "# Create a DataFrame with model metrics\n",
        "best_rf_model_df = pd.DataFrame({'Training Score': [best_rf_model.score(x_train, y_train)],\n",
        "                                'Validation Score': [best_rf_score_val],\n",
        "                                'RMSE': [best_rf_rmse],\n",
        "                                'R Squared': [best_rf_r2]})\n",
        "display(best_rf_model_df)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mdudcYBUx3mY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}