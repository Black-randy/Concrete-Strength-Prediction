{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "_S30YVRjYmjb",
        "8-WS5eOwi6If"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title **Step 0:** Get Necessary Libraries\n",
        "# Install required libraries\n",
        "!pip install seaborn\n",
        "!pip install wget pandas\n",
        "\n",
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import wget\n",
        "import os\n",
        "import shutil\n",
        "from IPython.display import display, clear_output\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "# Additional imports for data manipulation and analysis\n",
        "from scipy.stats import zscore\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "\n"
      ],
      "metadata": {
        "id": "ar1RXZnaluGe",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2KQICIcedDu",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title **Step 1 :** Download From Github and Organize Data\n",
        "\n",
        "# Function to download and organize data\n",
        "def download_and_organize_data():\n",
        "    # URLs of the files on GitHub\n",
        "    url_concrete_data_yeh = \"https://raw.githubusercontent.com/Black-randy/Concrete-Strength-Prediction/main/Concrete_Data_Yeh.csv\"\n",
        "    # Specify the destination paths in Google Colab\n",
        "    destination_path_train = \"/content/train_data/Concrete_Data_Yeh.csv\"\n",
        "    # Create folders for train data\n",
        "    os.makedirs(\"/content/train_data\", exist_ok=True)\n",
        "    # Download the file\n",
        "    wget.download(url_concrete_data_yeh, destination_path_train)\n",
        "    # Clear the output\n",
        "    clear_output()\n",
        "    # Print a message indicating the completion of the download and organization\n",
        "    print(\"Files downloaded and organized into train_data folder.\")\n",
        "# Download and organize data\n",
        "download_and_organize_data()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Step 2 :** Load Data into Pandas DataFrames\n",
        "\n",
        "# Function to load data into Pandas DataFrames\n",
        "def load_data_into_dataframes(train_data_path):\n",
        "    try:\n",
        "        # Load CSV files into Pandas DataFrames\n",
        "        train_df = pd.read_csv(os.path.join(train_data_path, \"Concrete_Data_Yeh.csv\"))\n",
        "\n",
        "        # Clear previous outputs\n",
        "        clear_output()\n",
        "\n",
        "        # Print the assigned values and display a preview of the DataFrames\n",
        "        print(f\"train_data_path: {train_data_path}\")\n",
        "\n",
        "        # Return the DataFrame\n",
        "        return train_df\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File not found at {train_data_path}\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"Error: An unexpected error occurred - {e}\")\n",
        "        return None\n",
        "\n",
        "# Assign values to train_data_path\n",
        "train_data_path = \"/content/train_data\"\n",
        "\n",
        "# Load data into Pandas DataFrame\n",
        "train_df = load_data_into_dataframes(train_data_path)\n"
      ],
      "metadata": {
        "id": "p5huPkcwf1dt",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Step 2.1 :** Train DataFrame info\n",
        "\n",
        "def display_dataframe_info(df, df_name=\"Train\"):\n",
        "    print(f\"\\n\\033[1m\\033[94mShape of the {df_name} DataFrame:\\033[0m\\n\")\n",
        "    rows_count, columns_count = df.shape\n",
        "    print(f'\\033[1mTotal Number of rows:\\033[0m {rows_count}')\n",
        "    print(f'\\033[1mTotal Number of columns:\\033[0m {columns_count}')\n",
        "\n",
        "    # Display a preview of the DataFrame\n",
        "    print(f\"\\n\\033[1m\\033[94mPreview of {df_name} DataFrame:\\033[0m\\n\")\n",
        "    display(df.head(4))\n",
        "\n",
        "    # Display data types of each attribute in the DataFrame\n",
        "    data_types = df.dtypes\n",
        "    print(f\"\\n\\033[1m\\033[94mData Types of Attributes in {df_name} DataFrame:\\033[0m\\n\")\n",
        "    print(data_types)\n",
        "\n",
        "    # Check for missing values in the DataFrame\n",
        "    missing_values = df.isnull().sum()\n",
        "\n",
        "    # Display the results\n",
        "    print(f\"\\n\\033[1m\\033[91mMissing Values in {df_name} DataFrame:\\033[0m\\n\")\n",
        "    print(missing_values[missing_values > 0])\n",
        "\n",
        "    # Display descriptive statistics for the DataFrame\n",
        "    descriptive_stats = df.describe()\n",
        "\n",
        "    # Print the results\n",
        "    print(f\"\\n\\033[1m\\033[94mDescriptive Statistics for {df_name} DataFrame:\\033[0m\")\n",
        "    display(descriptive_stats)\n",
        "\n",
        "# Display information for the train DataFrame\n",
        "display_dataframe_info(train_df, \"Train\")\n",
        "\n",
        "# Display information for the test DataFrame\n",
        "# display_dataframe_info(test_df, \"Test\")\n"
      ],
      "metadata": {
        "id": "X_GnBh67XxdP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Step 3 :** Visualize Feature Importances\n",
        "\n",
        "# Constants\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "def concatenate_dataframes(train_df, test_df=None):\n",
        "    # Concatenate train and test data\n",
        "    if test_df is not None:\n",
        "        combined_df = pd.concat([train_df, test_df], ignore_index=True)\n",
        "    else:\n",
        "        combined_df = train_df.copy()\n",
        "\n",
        "    return combined_df\n",
        "\n",
        "def visualize_feature_importances(X, y, random_state=RANDOM_STATE):\n",
        "    # Create a Random Forest Regressor\n",
        "    rf_model = RandomForestRegressor(n_estimators=100, random_state=random_state)\n",
        "\n",
        "    # Fit the model\n",
        "    rf_model.fit(X, y)\n",
        "\n",
        "    # Get feature importances\n",
        "    feature_importances = rf_model.feature_importances_\n",
        "\n",
        "    # Create a DataFrame to hold feature names and their importances\n",
        "    feature_importance_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "\n",
        "    # Sort features by importance in descending order\n",
        "    feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "    # Plot the feature importances\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.barh(feature_importance_df['Feature'], feature_importance_df['Importance'])\n",
        "    plt.xlabel('Importance')\n",
        "    plt.title('Feature Importances')\n",
        "    plt.show()\n",
        "\n",
        "# Concatenate data\n",
        "combined_df = concatenate_dataframes(train_df)  # Modify if test_df is needed\n",
        "\n",
        "# Separate features and target variable\n",
        "X = combined_df.drop(columns=['csMPa'])\n",
        "y = combined_df['csMPa']\n",
        "\n",
        "# Visualize feature importances\n",
        "visualize_feature_importances(X, y)\n"
      ],
      "metadata": {
        "id": "tYi9jFr7j0jg",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Pair Plot of All Columns\n",
        "\n",
        "#Set the style of seaborn\n",
        "# sns.set(style=\"ticks\")\n",
        "\n",
        "#Create a pair plot for all columns\n",
        "# plt.figure(figsize=(18, 15))\n",
        "# sns.pairplot(combined_df, markers=\"h\", diag_kind='kde')\n",
        "# plt.suptitle(\"Pair Plot of All Columns\", y=1.02, fontsize=20)\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "wsuRqO1BqSG2",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visualize Outliers\n",
        "\n",
        "def visualize_outliers(data, columns_of_interest, palette=\"Set3\"):\n",
        "    # Set the style of seaborn\n",
        "    sns.set(style=\"whitegrid\")\n",
        "\n",
        "    # Create a horizontal box plot for each column to visualize outliers\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    sns.boxplot(data=data[columns_of_interest], orient=\"h\", palette=palette, dodge=False)\n",
        "    plt.title('Horizontal Box Plot of Features to Visualize Outliers')\n",
        "    plt.show()\n",
        "\n",
        "# Select relevant columns for visualization\n",
        "columns_of_interest = ['cement', 'slag', 'flyash', 'water', 'superplasticizer', 'coarseaggregate', 'fineaggregate', 'age', 'csMPa']\n",
        "\n",
        "# Visualize outliers using \"Set3\" palette\n",
        "visualize_outliers(combined_df, columns_of_interest, palette=\"Set3\")\n"
      ],
      "metadata": {
        "id": "AUAMfvU8lFBI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Outliers Visualization**\n",
        "---"
      ],
      "metadata": {
        "id": "_S30YVRjYmjb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# @title Outliers Visualization\n",
        "features_of_interest = ['cement', 'slag', 'flyash', 'water', 'superplasticizer', 'coarseaggregate', 'fineaggregate', 'age', 'csMPa']\n",
        "\n",
        "# Set the style of seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Create subplots\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(6,6))\n",
        "\n",
        "# Flatten the axes for easy iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through each feature and create histograms and boxplots\n",
        "for i, feature in enumerate(features_of_interest):\n",
        "    sns.histplot(train_df[feature], kde=True, ax=axes[i])\n",
        "    axes[i].set_xlabel(feature, fontsize=8)\n",
        "    axes[i].set_title(f\"{feature} Distribution Plot\", fontsize=8)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Box plots for each feature\n",
        "fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(6,6))\n",
        "\n",
        "# Flatten the axes for easy iteration\n",
        "axes = axes.flatten()\n",
        "\n",
        "# Loop through each feature and create boxplots\n",
        "for i, feature in enumerate(features_of_interest):\n",
        "    sns.boxplot(train_df[feature], ax=axes[i])\n",
        "    axes[i].set_xlabel(feature, fontsize=8)\n",
        "    axes[i].set_title(f\"{feature} Box Plot\", fontsize=8)\n",
        "\n",
        "# Adjust layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "'''"
      ],
      "metadata": {
        "cellView": "form",
        "id": "MjPDB7WhXFMo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Cement Outliers Visualization\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n",
        "fig.set_size_inches(10, 3)\n",
        "# Distribution Plot\n",
        "sns.histplot(train_df['cement'], ax=ax1, kde=True)\n",
        "ax1.tick_params(labelsize=12)\n",
        "ax1.set_xlabel('Cement', fontsize=12)\n",
        "ax1.set_title(\"Distribution Plot\", fontsize=15)\n",
        "\n",
        "# Box Plot\n",
        "sns.boxplot(train_df['cement'], ax=ax2)\n",
        "ax2.set_title(\"Box Plot\", fontsize=15)\n",
        "ax2.set_xlabel('Cement', fontsize=12)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "26YE9mw95rhq",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Slag Outliers Visualization\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
        "fig.set_size_inches(12,5)\n",
        "\n",
        "# Distribution Plot\n",
        "sns.histplot(train_df['slag'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Slag', fontsize=12)  # Adjusted font size\n",
        "ax1.set_title(\"Distribution Plot\", fontsize=15)\n",
        "\n",
        "# Box Plot\n",
        "sns.boxplot(train_df['slag'], ax=ax2)\n",
        "ax2.set_xlabel('Slag', fontsize=12)  # Adjusted font size\n",
        "ax2.set_title(\"Box Plot\", fontsize=15)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "joctOSG-7dCC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Flyash Outliers Visualization\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
        "fig.set_size_inches(12,5)\n",
        "sns.histplot(train_df['flyash'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Flyash', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['flyash'], ax=ax2)\n",
        "ax2.set_xlabel('Flyash', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")\n"
      ],
      "metadata": {
        "id": "G6bVFOqL_kjb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Water Outliers Visualization\n",
        "# Water\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
        "fig.set_size_inches(12,5)\n",
        "sns.histplot(train_df['water'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Water', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['water'], ax=ax2)\n",
        "ax2.set_xlabel('Water', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")"
      ],
      "metadata": {
        "id": "kv-7knxL_oC_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Superplasticizer Outliers Visualization\n",
        "# Superplasticizer\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
        "fig.set_size_inches(12,5)\n",
        "\n",
        "sns.histplot(train_df['superplasticizer'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Superplasticizer', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['superplasticizer'], ax=ax2)\n",
        "ax2.set_xlabel('Superplasticizer', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")\n"
      ],
      "metadata": {
        "id": "WgQruWQlAX_B",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Coarseagg Outliers Visualization\n",
        "# Coarseagg\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
        "fig.set_size_inches(12,5)\n",
        "sns.histplot(train_df['coarseaggregate'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Coarseagg', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['coarseaggregate'], ax=ax2)\n",
        "ax2.set_xlabel('Coarseagg', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")"
      ],
      "metadata": {
        "id": "wIIowI4HC5qf",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Fineaggregate Outliers Visualization\n",
        "# Fineaggregate\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
        "fig.set_size_inches(12,5)\n",
        "sns.histplot(train_df['fineaggregate'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Fineagg', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['fineaggregate'], ax=ax2)\n",
        "ax2.set_xlabel('Fineagg', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")"
      ],
      "metadata": {
        "id": "2MhNDHQEC6s_",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Age Outliers Visualization\n",
        "# Age\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
        "fig.set_size_inches(12,5)\n",
        "sns.histplot(train_df['age'], ax=ax1, kde=True)\n",
        "ax1.set_xlabel('Age', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['age'], ax=ax2)\n",
        "ax2.set_xlabel('Age', fontsize=15)\n",
        "ax2.set_title(\"Box Plot\")\n",
        "\n",
        "Q1_age = train_df['age'].quantile(0.25)\n",
        "Q3_age = train_df['age'].quantile(0.75)\n",
        "IQR_age = Q3_age - Q1_age\n",
        "LTV_age = Q1_age - 1.5 * IQR_age\n",
        "UTV_age = Q3_age + 1.5 * IQR_age"
      ],
      "metadata": {
        "id": "k0FXO9TUC-M6",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Strength Outliers Visualization\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 5))\n",
        "fig.set_size_inches(12,5)\n",
        "sns.histplot(train_df['csMPa'], ax=ax1, kde=True)\n",
        "ax1.tick_params(labelsize=15)\n",
        "ax1.set_xlabel('Strength', fontsize=15)\n",
        "ax1.set_title(\"Distribution Plot\")\n",
        "\n",
        "sns.boxplot(train_df['csMPa'], ax=ax2)\n",
        "ax2.set_title(\"Box Plot\")\n",
        "ax2.set_xlabel('Strength', fontsize=15)"
      ],
      "metadata": {
        "id": "I9Ew0b1wDFpK",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fixing Outliers**\n",
        "---"
      ],
      "metadata": {
        "id": "nEIhNTTgMtyu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Fix Outliers and Visualize\n",
        "\n",
        "def fix_outliers(df):\n",
        "    df_new = df.copy()\n",
        "\n",
        "    # Iterate over each column (excluding the last one, assuming it's the target variable)\n",
        "    for col_name in df_new.columns[:-1]:\n",
        "        q1 = df_new[col_name].quantile(0.25)\n",
        "        q3 = df_new[col_name].quantile(0.75)\n",
        "        iqr = q3 - q1\n",
        "        low = q1 - 1.5 * iqr\n",
        "        high = q3 + 1.5 * iqr\n",
        "\n",
        "        # Replace values outside the lower and upper bounds with the median of the column\n",
        "        df_new.loc[(df_new[col_name] < low) | (df_new[col_name] > high), col_name] = df_new[col_name].median()\n",
        "\n",
        "    return df_new\n",
        "\n",
        "# Create a new DataFrame for fixing outliers\n",
        "train_df_new = fix_outliers(train_df)\n",
        "\n",
        "# Set the style of seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot boxplot after fixing outliers\n",
        "plt.figure(figsize=(15, 8))\n",
        "sns.boxplot(data=train_df_new, orient=\"h\", palette=\"Set2\", dodge=False)\n",
        "plt.title('Box Plot after Fixing Outliers')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9mhOIavBUufI",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Calculate and Visualize Correlation Matrix\n",
        "\n",
        "def visualize_correlation_matrix(df, cmap=\"RdPu\", annot=True):\n",
        "    correlation_matrix = df.corr()\n",
        "\n",
        "    # Create a mask for the upper triangle\n",
        "    mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "\n",
        "    # Set up the matplotlib figure with seaborn style\n",
        "    with sns.axes_style(\"white\"):\n",
        "        plt.figure(figsize=(7, 6))\n",
        "\n",
        "        # Draw the heatmap with the mask\n",
        "        sns.heatmap(correlation_matrix, cmap=cmap, annot=annot, fmt=\".2f\", linewidths=\".25\")\n",
        "\n",
        "        # Set the title with a smaller font size\n",
        "        plt.title(\"Correlation Matrix\", fontsize=10)\n",
        "\n",
        "        # Show the plot\n",
        "        plt.show()\n",
        "\n",
        "# Visualize the correlation matrix for train_df_new\n",
        "visualize_correlation_matrix(train_df_new)\n"
      ],
      "metadata": {
        "id": "uxv1_LD3Wkoc",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title KMeans Clustering for Optimal Number of Clusters\n",
        "\n",
        "def find_optimal_clusters(data, cluster_range):\n",
        "    cluster_errors = []\n",
        "\n",
        "    for num_clusters in cluster_range:\n",
        "        kmeans = KMeans(num_clusters, n_init=5)\n",
        "        kmeans.fit(data)\n",
        "        cluster_errors.append(kmeans.inertia_)\n",
        "\n",
        "    clusters_df = pd.DataFrame({\"num_clusters\": cluster_range, \"cluster_errors\": cluster_errors})\n",
        "    return clusters_df\n",
        "\n",
        "def plot_elbow_plot(clusters_df):\n",
        "    plt.figure(figsize=(4, 3))\n",
        "    plt.plot(clusters_df.num_clusters, clusters_df.cluster_errors, marker=\"o\")\n",
        "    plt.title('Elbow Plot for Optimal Number of Clusters')\n",
        "    plt.xlabel('Number of Clusters')\n",
        "    plt.ylabel('Cluster Errors (Inertia)')\n",
        "    plt.show()\n",
        "\n",
        "# Set the range of clusters to explore\n",
        "cluster_range = range(2, 6)\n",
        "\n",
        "# Find optimal clusters and plot elbow plot\n",
        "clusters_df = find_optimal_clusters(train_df_new, cluster_range)\n",
        "display(clusters_df)\n",
        "plot_elbow_plot(clusters_df)\n"
      ],
      "metadata": {
        "id": "TQ9PLNejcfR4",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title  Assigne cluster IDs to each data point\n",
        "num_clusters = 3\n",
        "\n",
        "# Create a KMeans model with the specified number of clusters\n",
        "kmeans_model = KMeans(n_clusters=num_clusters, random_state=2354)\n",
        "\n",
        "# Fit the model to the training data\n",
        "kmeans_model.fit(train_df_new)\n",
        "\n",
        "# Predict the cluster labels for each data point\n",
        "cluster_labels = kmeans_model.predict(train_df_new)\n",
        "\n",
        "# Assign the cluster labels to the original DataFrame\n",
        "train_df_new[\"Cluster_id\"] = cluster_labels\n",
        "\n",
        "# Create a deep copy of the DataFrame with cluster assignments\n",
        "train_df_new_clustered = train_df_new.copy(deep=True)"
      ],
      "metadata": {
        "id": "Ujq2EQZlfUTC",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Display Cluster Centers\n",
        "centroids = kmeans_model.cluster_centers_\n",
        "\n",
        "# 'centroids' is now a NumPy array containing the coordinates of the cluster centers\n",
        "print(\"Cluster Centers:\")\n",
        "print(centroids)\n"
      ],
      "metadata": {
        "id": "5RLprSWVl5kJ",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Z-Score Scaling\n",
        "\n",
        "def scale_dataframe(df):\n",
        "    # Apply z-score scaling to the DataFrame\n",
        "    df_scaled = df.apply(zscore)\n",
        "    return df_scaled\n",
        "\n",
        "# Scale the train_df_new DataFrame\n",
        "train_df_scaled = scale_dataframe(train_df_new)\n",
        "\n",
        "# Set the style of seaborn\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# Plot boxplot after scaling\n",
        "plt.figure(figsize=(6, 3))\n",
        "sns.boxplot(data=train_df_scaled, orient=\"h\", palette=\"Set2\", dodge=False)\n",
        "plt.title('Box Plot after Z-Score Scaling')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Zl0aEBLylB0Q",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Negelect theese**"
      ],
      "metadata": {
        "id": "8-WS5eOwi6If"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "jTm55spvcVIu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_new.head()"
      ],
      "metadata": {
        "id": "YI_dIm_BcFuO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_scaled.head()"
      ],
      "metadata": {
        "id": "7UYJOXe6bs0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA** Test Splitting"
      ],
      "metadata": {
        "id": "dz7mRqCt7gu0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <s> **Step xx :** Separating  csMPa  </s> --- not in use\n",
        "# x = train_df_new.drop(columns=['csMPa'])\n",
        "# y = train_df_new['csMPa']"
      ],
      "metadata": {
        "cellView": "form",
        "id": "biygdVu4rvzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Step xx :** Separating **csMPa** (Scaled) and Train-Test Split\n",
        "\n",
        "\n",
        "def perform_train_test_split(data, target_column='csMPa', test_size=0.2, random_state=7):\n",
        "    # Separate the target variable\n",
        "    y = data[target_column]\n",
        "    X = data.drop(columns=[target_column])\n",
        "\n",
        "    # Perform train-test split\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Display the shapes of the resulting data sets\n",
        "    print('X_train data shape: {}'.format(X_train.shape))\n",
        "    print('y_train data shape: {}'.format(y_train.shape))\n",
        "    print('X_test data shape : {}'.format(X_test.shape))\n",
        "    print('y_test data shape : {}'.format(y_test.shape))\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Perform the train-test split\n",
        "x_model_train, x_test, y_model_train, y_test = perform_train_test_split(train_df_scaled)\n"
      ],
      "metadata": {
        "id": "WLrw9vQ09FEA",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Step xx :** Separating **csMPa** (Scaled) and Train-Validation Split\n",
        "def perform_train_validation_split(X, y, test_size=0.3, random_state=7):\n",
        "    # Perform train-validation split\n",
        "    X_train, X_validate, y_train, y_validate = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
        "\n",
        "    # Display the shapes of the resulting data sets\n",
        "    print('X_train data shape: {}'.format(X_train.shape))\n",
        "    print('y_train data shape: {}'.format(y_train.shape))\n",
        "    print('X_validate data shape: {}'.format(X_validate.shape))\n",
        "    print('y_validate data shape: {}'.format(y_validate.shape))\n",
        "\n",
        "    return X_train, X_validate, y_train, y_validate\n",
        "\n",
        "# Perform the train-validation split\n",
        "x_train, x_validate, y_train, y_validate = perform_train_validation_split(x_model_train, y_model_train)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WVpLGqwKvkTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Models**"
      ],
      "metadata": {
        "id": "26M5UvXuIMiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Defining the kFold function for cross-validation\n",
        "\n",
        "\n",
        "def kfold_cross_validation(model, X, y, n_splits=10, random_state=7):\n",
        "    # Set the random seed using numpy\n",
        "    np.random.seed(random_state)\n",
        "\n",
        "    # Create a KFold object with shuffle=False\n",
        "    kfold = KFold(n_splits=n_splits, shuffle=False)\n",
        "\n",
        "    model_scores = []\n",
        "    model_RMSEs = []\n",
        "    model_R2s = []\n",
        "\n",
        "    for train_idx, test_idx in kfold.split(X):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Predict on the test set\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate and store model metrics\n",
        "        score = model.score(X_test, y_test)\n",
        "        RMSE = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "        R2 = r2_score(y_test, y_pred)\n",
        "\n",
        "        model_scores.append(score)\n",
        "        model_RMSEs.append(RMSE)\n",
        "        model_R2s.append(R2)\n",
        "\n",
        "    return model_scores, model_RMSEs, model_R2s\n",
        "\n",
        "# Example usage with a linear regression model\n",
        "linear_model = LinearRegression()\n",
        "linear_model_scores, linear_model_RMSEs, linear_model_R2s = kfold_cross_validation(linear_model, x_model_train, y_model_train)\n",
        "\n",
        "# Print or store the results as needed\n"
      ],
      "metadata": {
        "id": "BUaHZK1tkedP",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Model X.1 :** Linear Regression Model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random_state = 7\n",
        "\n",
        "# Initialize Linear Regression model\n",
        "regression_model = LinearRegression()\n",
        "\n",
        "# Fit the Linear Regression model on the training data\n",
        "regression_model.fit(x_train, y_train)\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*13 + \"Linear Regression Model\" + \"-\"*13 + \"\\n\")\n",
        "\n",
        "# Display coefficients for each independent attribute\n",
        "for idx, col_name in enumerate(x_train.columns):\n",
        "    print(f\"The coefficient for {col_name} is: {regression_model.coef_[idx]}\")\n",
        "\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Display the intercept for the model\n",
        "intercept = regression_model.intercept_\n",
        "print(f\"Model intercept is {intercept}\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "lr_score = regression_model.score(x_validate, y_validate)\n",
        "print(f\"Linear Regression Model Score: {lr_score}\")\n",
        "\n",
        "# Calculate RMSE using cross-validation\n",
        "kfold = KFold(n_splits=10, shuffle=True, random_state=random_state)\n",
        "lr_rmse = np.sqrt((-1) * cross_val_score(regression_model, x_train, y_train.values.ravel(), cv=kfold, scoring='neg_mean_squared_error').mean())\n",
        "print(f\"Linear Regression Model RMSE : {lr_rmse}\")\n",
        "\n",
        "# Calculate R-squared using cross-validation\n",
        "lr_r2 = cross_val_score(regression_model, x_train, y_train.values.ravel(), cv=kfold, scoring='r2').mean()\n",
        "print(f\"Linear Regression Model R-Square Value: {lr_r2}\")\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n"
      ],
      "metadata": {
        "id": "tyBRdE2vtZ5N",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Model X.2 :** Multilinear Regression Model\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "def display_model_information(model, X, y, X_validate, y_validate, model_name):\n",
        "    # Initialize the model\n",
        "    mlr_model = model\n",
        "\n",
        "    # Fit the model on the training data\n",
        "    mlr_model.fit(X, y)\n",
        "\n",
        "    # Add a space\n",
        "    print(f\"\\n{'-'*13}{model_name}{'-'*13}\\n\")\n",
        "\n",
        "    # Display coefficients for each independent attribute\n",
        "    print(\"Coefficients for each independent attribute:\")\n",
        "    for idx, col_name in enumerate(X.columns):\n",
        "        print(f\"The coefficient for {col_name} is: {mlr_model.coef_[idx]}\")\n",
        "\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "    # Evaluate the model on the validation set\n",
        "    mlr_score = mlr_model.score(X_validate, y_validate)\n",
        "    print(f\"{model_name} Score:\", mlr_score)\n",
        "\n",
        "    # Calculate RMSE using cross-validation\n",
        "    mlr_rmse = np.sqrt((-1) * cross_val_score(mlr_model, X, y.values.ravel(), cv=kfold, scoring='neg_mean_squared_error').mean())\n",
        "    print(f\"{model_name} RMSE: {mlr_rmse}\")\n",
        "\n",
        "    # Calculate R-squared using cross-validation\n",
        "    mlr_r2 = cross_val_score(mlr_model, X, y.values.ravel(), cv=kfold, scoring='r2').mean()\n",
        "    print(f\"{model_name} R-Square Value: {mlr_r2}\")\n",
        "\n",
        "    # Add a space\n",
        "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Example usage\n",
        "mlr_model_instance = LinearRegression()\n",
        "display_model_information(mlr_model_instance, x_train, y_train, x_validate, y_validate, \"Multilinear Regression Model\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "AbMBBvxRSmYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title <del> **Model xx :**  Train Random Forest Classifier. </del>\n",
        "\n",
        "'''\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Convert the target variable to binary labels for classification\n",
        "threshold = 1\n",
        "y_train_class = (y_train > threshold).astype(int)\n",
        "y_test_class = (y_test > threshold).astype(int)\n",
        "\n",
        "# Create and fit the Random Forest Classifier model\n",
        "rf_classifier_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_classifier_model.fit(x_train, y_train_class)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_predict_class = rf_classifier_model.predict(x_test)\n",
        "\n",
        "# Evaluate the Random Forest Classifier performance\n",
        "accuracy = accuracy_score(y_test_class, y_predict_class)\n",
        "classification_rep = classification_report(y_test_class, y_predict_class)\n",
        "conf_matrix = confusion_matrix(y_test_class, y_predict_class)\n",
        "\n",
        "# Print performance metrics\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_rep)\n",
        "print(\"\\nConfusion Matrix:\\n\", conf_matrix)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=['Not High Strength', 'High Strength'],\n",
        "            yticklabels=['Not High Strength', 'High Strength'])\n",
        "plt.title('Confusion Matrix for Random Forest Classifier')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.show()'''\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "586fsWV6UdIo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Model X.3 :** Random Forest Regressor Model\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Define a range of n_estimators for hyperparameter tuning\n",
        "n_estimators = [int(x) for x in np.linspace(start=10, stop=100, num=3)]\n",
        "\n",
        "# Initialize a Random Forest Regressor with default parameters\n",
        "rfTree = RandomForestRegressor()\n",
        "\n",
        "# Fit the Random Forest Regressor on the training data\n",
        "rfTree.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*13 + \"Random Forest Regressor Model\" + \"-\"*13 + \"\\n\")\n",
        "\n",
        "# Evaluate the model on the training set\n",
        "rfTree_train_score = rfTree.score(x_train, y_train)\n",
        "print(f\"Training Set Score: {rfTree_train_score:.4f}\")\n",
        "\n",
        "# Evaluate the model on the validation set\n",
        "rfTree_score = rfTree.score(x_validate, y_validate)\n",
        "print(f\"Validation Set Score: {rfTree_score:.4f}\")\n",
        "\n",
        "# Calculate RMSE using cross-validation\n",
        "rfTree_rmse = np.sqrt((-1) * cross_val_score(rfTree, x_train, y_train.values.ravel(), cv=kfold, scoring='neg_mean_squared_error').mean())\n",
        "print(f\"RMSE: {rfTree_rmse:.4f}\")\n",
        "\n",
        "# Calculate R-squared using cross-validation\n",
        "rfTree_r2 = cross_val_score(rfTree, x_train, y_train.values.ravel(), cv=kfold, scoring='r2').mean()\n",
        "print(f\"R-Square Value: {rfTree_r2:.4f}\")\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Create a DataFrame with model metrics\n",
        "rfTree_model_df = pd.DataFrame({'Training Score': [rfTree_train_score],\n",
        "                                'Validation Score': [rfTree_score],\n",
        "                                'RMSE': [rfTree_rmse],\n",
        "                                'R Squared': [rfTree_r2]})\n",
        "display(rfTree_model_df)\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "rfTree_test_score = rfTree.score(x_test, y_test)\n",
        "print(f\"Test Data Set Score: {rfTree_test_score:.4f}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "e7dPlkA92KPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title **Model X.3.1 :** Hyper-tuning Random Forest Regressor - **Gridsearch CV**\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "import sys\n",
        "\n",
        "# Define the parameter distribution\n",
        "param_dist = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [10],\n",
        "    'max_features': ['log2'],\n",
        "    'min_samples_leaf': [1, 2, 3],\n",
        "    'min_samples_split': sp_randint(5, 11),\n",
        "    'n_estimators': sp_randint(50, 71)\n",
        "}\n",
        "\n",
        "# Create a Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(random_state=7)\n",
        "\n",
        "# Create RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(\n",
        "    estimator=rf_model,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    cv=kfold,\n",
        "    n_jobs=1,\n",
        "    verbose=0,\n",
        "    return_train_score=True,\n",
        "    random_state=7\n",
        ")\n",
        "\n",
        "# Redirect standard output to capture progress\n",
        "original_stdout = sys.stdout\n",
        "sys.stdout = sys.stderr\n",
        "\n",
        "# Fit the random search to the data\n",
        "print(\"Fitting RandomizedSearchCV...\")\n",
        "random_search.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "# Reset standard output\n",
        "sys.stdout = original_stdout\n",
        "\n",
        "# Get the best parameters and model\n",
        "best_params = random_search.best_params_\n",
        "best_rf_model = random_search.best_estimator_\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best Parameters:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Fit the best model on the training set\n",
        "best_rf_model.fit(x_train, y_train.values.ravel())\n",
        "\n",
        "# Evaluate the best model on the validation set\n",
        "best_rf_score_val = best_rf_model.score(x_validate, y_validate)\n",
        "print(f\"Validation Set Score: {best_rf_score_val:.4f}\")\n",
        "\n",
        "# Calculate RMSE using cross-validation\n",
        "best_rf_rmse = np.sqrt((-1) * cross_val_score(best_rf_model, x_train, y_train.values.ravel(), cv=kfold, scoring='neg_mean_squared_error').mean())\n",
        "print(f\"RMSE: {best_rf_rmse:.4f}\")\n",
        "\n",
        "# Calculate R-squared using cross-validation\n",
        "best_rf_r2 = cross_val_score(best_rf_model, x_train, y_train.values.ravel(), cv=kfold, scoring='r2').mean()\n",
        "print(f\"R-Square Value: {best_rf_r2:.4f}\")\n",
        "\n",
        "# Create a DataFrame with model metrics\n",
        "best_rf_model_df = pd.DataFrame({'Training Score': [best_rf_model.score(x_train, y_train)],\n",
        "                                  'Validation Score': [best_rf_score_val],\n",
        "                                  'RMSE': [best_rf_rmse],\n",
        "                                  'R Squared': [best_rf_r2]})\n",
        "display(best_rf_model_df)\n",
        "print(f\"Test Data Set Score: {rfTree_test_score:.4f}\")\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mdudcYBUx3mY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from IPython.display import display\n",
        "\n",
        "\n",
        "# Display information for Random Forest Regressor Model\n",
        "rfTree_model_df = pd.DataFrame({'Trainng Score': [rfTree_train_score],\n",
        "                                'Validation Score': [rfTree_score],\n",
        "                                'RMSE': [rfTree_rmse],\n",
        "                                'R Squared': [rfTree_r2]})\n",
        "display(rfTree_model_df)\n",
        "# Evaluate the model on the test set\n",
        "rfTree_test_score = rfTree.score(x_test, y_test)\n",
        "print(f\"\\nTest Data Set Score (Random Forest): {rfTree_test_score:.4f}\")\n",
        "\n",
        "# Add a space\n",
        "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
        "\n",
        "# Display information for Best Random Forest Regressor Model\n",
        "best_rf_model_df = pd.DataFrame({'Training Score': [best_rf_model.score(x_train, y_train)],\n",
        "                                  'Validation Score': [best_rf_score_val],\n",
        "                                  'RMSE': [best_rf_rmse],\n",
        "                                  'R Squared': [best_rf_r2]})\n",
        "display(best_rf_model_df)\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the best model on the test set\n",
        "best_rf_test_score = best_rf_model.score(x_test, y_test)\n",
        "print(f\"\\nTest Data Set Score (Best Random Forest): {best_rf_test_score:.4f}\")\n"
      ],
      "metadata": {
        "id": "008045TWeTCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s-aahpJEmhsu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
